{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Jupyter Notebooks with Galileo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Galileo makes using Jupyter Notebooks as easy as running a Python script. This short example notebook demonstrates how using a Jupyter notebook with Galileo is just like running a notebook locally.\n",
    "\n",
    "This example will use the famous iris data set to perform some exploratory data analysis as well as to train and test four classifiers, a decision tree, a random forest, a support vector classifier (SVC), and a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing the dependencies specified when creating the mission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from IPython.display import IFrame\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set() #  set the plotting style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the data set using the uploaded file and inspect the first five rows. The data set does not include a header for column names, so add those manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "df = pd.read_csv(\"iris.csv\", names=header_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on the Iris data set and original method Ronald Fisher used to classify the species, please watch this short video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"https://www.youtube.com/watch?v=PlrEJfvZRNo\", width=560, height=315)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can also be loaded from online sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n",
    "                 names=header_names)\n",
    "online_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use data included in loaded dependencies, such as the same iris data set included in the scikit-learn datasets module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "sk_df = pd.DataFrame(np.hstack((iris['data'], iris['target'].reshape(150,1))\n",
    "                               ),\n",
    "                     columns=header_names\n",
    "                     )\n",
    "sk_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With access to the data, we can now look at simple summary statistics to compare the three classes of *iris setosa*, *iris versicolor*, and *iris-virginica*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.groupby('species').agg([np.mean, np.std, min, max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to gain insight into the ways the variables interact with each other is to create a pair plot, which shows pairwise relationships in the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_plot = sns.pairplot(df, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pair plot suggests that *iris setosa* is linearly separable from the other species along a few axes but that *iris versicolor* and *iris virginica* might require more work to distinguish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use four different methods for classifying the iris flowers into the three species: a decision tree, and random forest, a suspport vector classifier, and logistic regression. In order to visualize the resulting models' decision boundaries, we will restrict the data set to only two dimensions: petal width and petal length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into training and testing sets to measure how well the models generalize to new data. We will withhold 20% of the data for use in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sk_df.drop([\n",
    "                                                                'sepal_width',\n",
    "                                                                'sepal_length',\n",
    "                                                                'species'\n",
    "                                                                ],\n",
    "                                                               axis=1).values,\n",
    "                                                    sk_df['species'].values,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=random_seed\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the four classifiers and specify any desired parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = DecisionTreeClassifier(random_state=random_seed)\n",
    "clf2 = RandomForestClassifier(random_state=random_seed)\n",
    "clf3 = SVC(random_state=random_seed, kernel='linear')\n",
    "clf4 = LogisticRegression(random_state=random_seed,\n",
    "                          max_iter=1000,\n",
    "                          solver='saga',\n",
    "                          multi_class='multinomial'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "labels = ['Decision Tree', 'Random Forest', 'SVC', 'Logistic Regression']\n",
    "for clf, lab, grd in zip([clf1, clf2, clf3, clf4],\n",
    "                         labels,\n",
    "                         itertools.product([0, 1], repeat=2)):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=X_test, y=y_test.astype(np.int64), clf=clf, legend=2)\n",
    "    plt.title(lab)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, \n",
    "              ['Iris setosa', 'Iris versicolor', 'Iris virginica'], \n",
    "               framealpha=0.3, scatterpoints=1)\n",
    "    ax.set_xlabel(\"Petal Length\")\n",
    "    ax.set_ylabel(\"Petal Width\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization shows how the different classification methods' internal mechanics dictate the construction of decision boundaries. The tree-based methods' decision boundaries are always parallel to the feature axes and the support vector classifier (with a linear kernel) and logistic regression have strictly linear boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short example notebook has demonstrated how a Jupyter Notebook on Galileo work identically to how a notebook works on a local machine, with support for loading data from a local drive, an online source, or from a dependency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}